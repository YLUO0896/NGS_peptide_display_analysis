{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Finished clustering stat.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog,ttk\n",
    "import os\n",
    "import time\n",
    "import Levenshtein as LV\n",
    "from glob import glob\n",
    "import re\n",
    "import csv\n",
    "##=================================== Define Functions ===========================================\n",
    "def convertN(sequence): # 由于简并碱基的复杂程度太高且不常见，将所有简并碱基视为N\n",
    "    return re.sub(r'[^ATCG]', 'N', sequence)\n",
    "#===============================================================================\n",
    "def translate(ncltseq,continu = 'N'):  # dna序列翻译到蛋白质序列, continu = 'N'则遇到终止密码子后不继续翻译，否则继续\n",
    "    codon_table = {'ATA':'I', 'ATC':'I', 'ATT':'I', 'ATG':'M','ACA':'T', 'ACC':'T', 'ACG':'T', 'ACT':'T',\n",
    "        'AAC':'N', 'AAT':'N', 'AAA':'K', 'AAG':'K','AGC':'S', 'AGT':'S', 'AGA':'R', 'AGG':'R',\n",
    "        'CTA':'L', 'CTC':'L', 'CTG':'L', 'CTT':'L','CCA':'P', 'CCC':'P', 'CCG':'P', 'CCT':'P',\n",
    "        'CAC':'H', 'CAT':'H', 'CAA':'Q', 'CAG':'Q','CGA':'R', 'CGC':'R', 'CGG':'R', 'CGT':'R',\n",
    "        'GTA':'V', 'GTC':'V', 'GTG':'V', 'GTT':'V', 'GCA':'A', 'GCC':'A', 'GCG':'A', 'GCT':'A',\n",
    "        'GAC':'D', 'GAT':'D', 'GAA':'E', 'GAG':'E', 'GGA':'G', 'GGC':'G', 'GGG':'G', 'GGT':'G',\n",
    "        'TCA':'S', 'TCC':'S', 'TCG':'S', 'TCT':'S', 'TTC':'F', 'TTT':'F', 'TTA':'L', 'TTG':'L',\n",
    "        'TAC':'Y', 'TAT':'Y', 'TAA':'*', 'TAG':'Q', 'TGC':'C', 'TGT':'C', 'TGA':'*', 'TGG':'W',\n",
    "        'GCN':'A', 'CGN':'R', 'GGN':'G', 'CTN':'L', 'CCN':'P', 'TCN':'S', 'GTN':'V'}\n",
    "    bplength = len(ncltseq)\n",
    "    output = ''\n",
    "    i = 0\n",
    "    while i in range (0,bplength):\n",
    "        codon = ncltseq[i:i+3]\n",
    "        if codon in codon_table.keys():\n",
    "            aminoacid = codon_table[codon]\n",
    "        else:\n",
    "            aminoacid = 'X'\n",
    "        output = output + aminoacid\n",
    "        i = i+3\n",
    "    return output\n",
    "\n",
    "def findcds(seq,consb,consa,cv_er):\n",
    "    try:\n",
    "        fidx = seq.index(consb)+len(consb)\n",
    "    except:\n",
    "        val0 = cv_er\n",
    "        fidx = False\n",
    "        for i in range(len(seq)-len(consb)):\n",
    "            char = seq[i:i+len(consb)]\n",
    "            val = LV.distance(char,consb)\n",
    "            if val <= val0:\n",
    "                fidx = i\n",
    "                val0 = val\n",
    "    try:\n",
    "        ridx = seq.index(consa)\n",
    "    except:\n",
    "        val0 = cv_er\n",
    "        ridx = False\n",
    "        for i in range(len(seq)-len(consa)):\n",
    "            char = seq[i:i+len(consa)]\n",
    "            val = LV.distance(char,consa)\n",
    "            if val <= val0:\n",
    "                ridx = i\n",
    "                val0 = val\n",
    "    if fidx != False and ridx != False:\n",
    "        cds = seq[fidx:ridx]\n",
    "        cds = convertN(cds)\n",
    "        return cds\n",
    "    else:\n",
    "        return 'NA'\n",
    "\n",
    "def deduplicate(info,atpl,al_er,total):\n",
    "    atpl = min(atpl,total)\n",
    "    total = min(total,len(info))\n",
    "    out = pd.DataFrame()   # <out> as the deduplicated collection\n",
    "    out.loc[0,'library seq']=info['library seq'][0]\n",
    "    out.loc[0,'count'] = info['count'][0]\n",
    "    outidx = 1\n",
    "    for i in range(1,total): # reduce calculation steps if too many sequence types\n",
    "        seq = info['library seq'][i]\n",
    "        if seq == 'NA':\n",
    "            continue\n",
    "        scount = info['count'][i]\n",
    "        status = False\n",
    "        for j in range(0,min(atpl,i,len(out))):\n",
    "            err = LV.distance(out['library seq'][j],seq)\n",
    "            if err <= al_er:\n",
    "                out.loc[j,'count'] += scount\n",
    "                status = True\n",
    "                break\n",
    "        if status == False: # if template not found in <out>\n",
    "            out.loc[outidx,'library seq'] = seq\n",
    "            out.loc[outidx,'count'] = scount\n",
    "            outidx += 1\n",
    "    out = out.sort_values(by = 'count', ascending = False)\n",
    "    return out\n",
    "\n",
    "def dedupprot(info,atpl,al_er,total):\n",
    "    atpl = min(atpl,total)\n",
    "    total = min(total,len(info))\n",
    "    out = pd.DataFrame()   # <out> as the deduplicated collection\n",
    "    out.loc[0,'protein seq']=info['protein seq'][0][0]\n",
    "    out.loc[0,'count'] = info['count'][0]\n",
    "    outidx = 1\n",
    "    for i in range(1,total): # reduce calculation steps if too many sequence types\n",
    "        seq = info['protein seq'][i][0]\n",
    "        if seq == 'NA' or seq == '*':\n",
    "            continue\n",
    "        scount = info['count'][i]\n",
    "        seq_lib = list(out['protein seq'])\n",
    "        if seq in seq_lib:\n",
    "            idx = seq_lib.index(seq)\n",
    "            out.loc[idx,'count'] += scount\n",
    "        else:\n",
    "            out.loc[outidx,'protein seq'] = seq\n",
    "            out.loc[outidx,'count'] = scount\n",
    "            outidx += 1\n",
    "    out = out.sort_values(by = 'count', ascending = False)\n",
    "    return out\n",
    "#===============================================================================\n",
    "##=================================== GUI Functions ===========================================\n",
    "def preview_txt():\n",
    "    folder_path = filedialog.askdirectory()\n",
    "    try:\n",
    "        sstr = os.path.join(folder_path, \"**\",'*√.txt')\n",
    "    except:\n",
    "        sstr = os.path.join(folder_path, \"**\",'*.txt')\n",
    "    global file_list\n",
    "    file_list = glob(sstr, recursive=True)\n",
    "    first_five_lines = ''\n",
    "    count = 0\n",
    "    with open(file_list[0], 'r',buffering = 1) as f1:\n",
    "        for line in f1:\n",
    "            first_five_lines += str(count+1)+ '. '+line\n",
    "            count += 1\n",
    "            if count == 10:\n",
    "                break\n",
    "    file_path_entry.delete(0, tk.END)\n",
    "    file_path_entry.insert(0, str(file_list))\n",
    "    text_box.delete('1.0', tk.END)\n",
    "    text_box.insert(tk.END, first_five_lines)\n",
    "    \n",
    "def show_default_consv():    ## Set default values\n",
    "    cb_entry.delete(0, tk.END)\n",
    "    cb_entry.insert(0,'CATGGCG')\n",
    "    ca_entry.delete(0, tk.END)\n",
    "    ca_entry.insert(0,'GGTTCTG')\n",
    "\n",
    "def use_default_param():\n",
    "    cv_er_entry.delete(0, tk.END)\n",
    "    cv_er_entry.insert(0,'2')\n",
    "    ab_tpl_entry.delete(0, tk.END)\n",
    "    ab_tpl_entry.insert(0,'50')\n",
    "    align_er_entry.delete(0, tk.END)\n",
    "    align_er_entry.insert(0,'4')\n",
    "    prcss_num_entry.delete(0, tk.END)\n",
    "    prcss_num_entry.insert(0,'20000')\n",
    "    \n",
    "def use_default_param2():\n",
    "    scale.set(66)\n",
    "    cluster_cnt_entry.delete(0, tk.END)\n",
    "    cluster_cnt_entry.insert(0,'200')\n",
    "#============================ Processing ==========================================    \n",
    "def submit1():  # translation\n",
    "    global file_list\n",
    "    consb = cb_entry.get().upper()\n",
    "    consa = ca_entry.get().upper()\n",
    "    cv_er = int(cv_er_entry.get())\n",
    "    atpl = int(ab_tpl_entry.get())\n",
    "    al_er = int(align_er_entry.get())\n",
    "    total = int(prcss_num_entry.get()) \n",
    "    for file in file_list:\n",
    "        print('>> Processing file: '+file)\n",
    "        try:\n",
    "            readin = pd.read_csv(file,header = None)\n",
    "        except:\n",
    "            readin = pd.read_csv(file,header = None,sep = '  ',engine = 'python')\n",
    "        statistics = readin[0].value_counts()\n",
    "        statistics.to_csv(file.replace('√.txt','-nt_stat.csv'),header = False)\n",
    "        print('>> Finished abundance stat of DNA sequences, start extracting library sequences and process deduplication.')\n",
    "        stidx = statistics.index.tolist()\n",
    "        stcnt = list(statistics)\n",
    "        info = pd.DataFrame()\n",
    "        info['DNA seq'] = stidx\n",
    "        info['count'] = stcnt\n",
    "        stcds = []\n",
    "        baddata = []\n",
    "        for i in range(len(stidx)):\n",
    "            seq = stidx[i]\n",
    "            count = stcnt[i]\n",
    "            cds = findcds(seq,consb,consa,cv_er)\n",
    "            if cds == 'NA':\n",
    "                baddata.append([count,'conserved seq not found',seq,'n.a.','n.a.'])\n",
    "            stcds.append(cds)\n",
    "        info['library seq'] = stcds\n",
    "        info = deduplicate(info,atpl,al_er,total)\n",
    "        info.to_csv(file.replace('√.txt','-nt_stat(dedup).csv'),header = True, index = False)\n",
    "        print('>> Finished deduplication of library DNA sequences, start translation stat.')\n",
    "        stprot = []\n",
    "        for i in range(len(info)):\n",
    "            cds = info['library seq'][i]  # the <info> collection has been deduplicated\n",
    "            count = info['count'][i]\n",
    "            if len(cds)%3 != 0:\n",
    "                baddata.append([count,'frame shift','full seq deduplicated',cds,'n.a.'])\n",
    "                stprot.append(['NA'])\n",
    "                continue\n",
    "            prot = translate(cds,continu = 'Y')\n",
    "            if '*' in prot:\n",
    "                baddata.append([count,'in-frame stop codon','full seq deduplicated',cds,prot])\n",
    "                stprot.append(['*',prot])\n",
    "                continue\n",
    "            stprot.append([prot])\n",
    "        info['protein seq'] = stprot\n",
    "        info = dedupprot(info,atpl,al_er,total)\n",
    "        info.to_csv(file.replace('√.txt','-aa_stat.csv'),header = True, index = False)\n",
    "        print('>> Finished translation stat.')\n",
    "        csvfile = open(file.replace('√.txt','-baddata.csv'),'w',newline='')\n",
    "        write = csv.writer(csvfile)\n",
    "        write.writerow(['Count','Problem','Full DNA Seq','Library DNA Seq','Library Protein Seq'])\n",
    "        write.writerows(baddata)\n",
    "        csvfile.close()\n",
    "        statistics, info, baddata = [],[],[]\n",
    "    react.config(text = 'Translation Finished.')\n",
    "##############################################################################\n",
    "def submit2():\n",
    "    global file_list\n",
    "    simi = scale.get()/100\n",
    "    total = int(cluster_cnt_entry.get())\n",
    "    i = 0\n",
    "    for file in file_list:\n",
    "        groups = {}\n",
    "        data = []\n",
    "        try:\n",
    "            file_path = file.replace('√.txt','-aa_stat.csv') # new version\n",
    "        except:\n",
    "            file_path = file.replace('.txt','-aa_stat.csv') # old version\n",
    "        with open(file_path,'r') as f:\n",
    "            for row in f:\n",
    "                data.append(row.strip(' \\n').split(','))\n",
    "                i += 1\n",
    "                if i == total:\n",
    "                    break\n",
    "        if data[0][0] == 'protein seq':\n",
    "            del data[0]\n",
    "        groups[data[0][0]] = [] # representative seqs stored as keys of a dict\n",
    "        for row in data:\n",
    "            seq = row[0]\n",
    "            if seq == '':\n",
    "                continue\n",
    "            state = False\n",
    "            for rep_seq in groups.keys():\n",
    "                dif = LV.distance(seq,rep_seq)/max(len(seq),len(rep_seq))\n",
    "                if dif <= 1-simi:   # if the difference between two pepseqs is smaller than preset value\n",
    "                    similarity = '{:.0f}%'.format(100*(1-dif))\n",
    "                    cys_cnt = seq.count('C')\n",
    "                    row = row+[similarity,cys_cnt]\n",
    "                    groups[rep_seq].append(row)\n",
    "                    state = True\n",
    "                    break\n",
    "                continue\n",
    "            if state == False:  # if not assigned, add a new group\n",
    "                similarity = '100%'\n",
    "                cys_cnt = seq.count('C')\n",
    "                row = row+[similarity,cys_cnt]\n",
    "                groups[seq] = [row]\n",
    "        csvfile = open(file_path.replace('-aa_stat.csv','-aa_clusters.csv'),'w',newline='')\n",
    "        write = csv.writer(csvfile)\n",
    "        write.writerow(['Peptide Seq','Quantity','Similarity','Cysteine Count'])\n",
    "        for i in range(len(list(groups.keys()))):\n",
    "            key = list(groups.keys())[i]\n",
    "            cnt = 0\n",
    "            for j in groups[key]:\n",
    "                cnt += int(float(j[1]))\n",
    "            write.writerow(['Family '+str(i+1)+': '+key+', Total Quantity: '+str(cnt)])\n",
    "            write.writerows(groups[key])\n",
    "    csvfile.close()\n",
    "    print('>> Finished clustering stat.')\n",
    "    react2.config(text = 'Clustering Finished.')\n",
    "#===============================================================================\n",
    "\n",
    "\n",
    "root = tk.Tk()\n",
    "root.title('NGS peptide - S4 Translation and Clustering')\n",
    "# Create entry field and button for input data file selection dialogue\n",
    "file_path_entry = tk.Entry(root, width = 85)\n",
    "file_path_entry.grid(row=0, column=3, columnspan=85, padx=10, pady=5)\n",
    "select_file_button = tk.Button(root, text=\"    Select File and Preview  \", command=preview_txt)\n",
    "select_file_button.grid(row=0, column= 86, columnspan = 35, padx=10, pady=5)\n",
    "\n",
    "# Create a text box to display the first 5 lines of the text file\n",
    "text_box = tk.Text(root, height=6, width=120)\n",
    "text_box.grid(row=3, column=0, columnspan=120, padx=10, pady=5)\n",
    "\n",
    "hyfen = tk.Label(root,text = '========== Translation Section ============================================================================= ',font = (\"Arial\", 10, \"bold\"))\n",
    "hyfen.grid(row=4,column = 0, columnspan = 125, padx = 10, pady = 5)\n",
    "\n",
    "# Create a text box to display default seq format\n",
    "tpl_box = tk.Text(root, height=4, width=80)\n",
    "tpl_box.insert(tk.END,'   Barcode        N-ter conserved              Library       C-ter conserved\\n  ======== ---------------------------- ==================== ---------------\\n  AGGAGTCC ATTCTATGCGGCCCAGCCGGCCATGGCG NNKTGC (NNK)n TGTNNK GGTTCTGGCGCTGAA\\n            |F||Y||A||A||Q||P||A||M||A| |X||C|  |X|n  |C||X| |G||S||G||A||E|')\n",
    "tpl_box.grid(row = 5, column = 30, columnspan = 80)\n",
    "tpl_label = tk.Label(root,text = 'The default format\\n of a sequence:')\n",
    "tpl_label.grid(row = 5, column =0, columnspan = 30, rowspan = 3)\n",
    "\n",
    "############### Set/Show default template format\n",
    "hyfen2 = tk.Label(root,text = '* ----------- * ----------- * ----------- * ----------- * ----------- * ----------- * ----------- * ----------- * ----------- * ----------- * ----------- * ----------- * ')\n",
    "hyfen2.grid(row=8,column = 0, columnspan = 120, padx = 10, pady = 5)\n",
    "\n",
    "cb_label = tk.Label(root, text='Conserved Seq before Library:' )\n",
    "cb_label.grid(row=9, column=0, columnspan=30, padx=5, pady=5)\n",
    "cb_entry = tk.Entry(root)\n",
    "cb_entry.grid(row=10, column=0, columnspan=30, padx=5, pady=5)\n",
    "clup_label = tk.Label(root, text='Library:' )\n",
    "clup_label.grid(row=9, column=30, columnspan=30, padx=5, pady=5)\n",
    "cl_label = tk.Label(root, text='NNKTGC (NNK)n TGTNNK' )\n",
    "cl_label.grid(row=10, column=30, columnspan=30, padx=5, pady=5)\n",
    "ca_label = tk.Label(root, text='Conserved Seq after Library:' )\n",
    "ca_label.grid(row=9, column=60, columnspan=30, padx=5, pady=5)\n",
    "ca_entry = tk.Entry(root)\n",
    "ca_entry.grid(row=10, column=60, columnspan=30, padx=5, pady=5)\n",
    "df_button = tk.Button(root,text = ' Use Default  \\n  Conserved Seq ',command = show_default_consv)\n",
    "df_button.grid(row = 9, column = 90, columnspan= 30, rowspan = 2, padx = 5, pady=5)\n",
    "\n",
    "hyfen3 = tk.Label(root,text = '* ----------- * ----------- * ----------- * ----------- * ----------- * ----------- * ----------- * ----------- * ----------- * ----------- * ----------- * ----------- * ')\n",
    "hyfen3.grid(row=11,column = 0, columnspan = 120, padx = 10, pady = 5)\n",
    "\n",
    "cv_error = tk.Label(root, text = 'Max Error per Conserved Seq (bp):')\n",
    "cv_error.grid(row = 12, column = 0, columnspan= 35, padx = 5, pady=5)\n",
    "cv_er_entry = tk.Entry(root, width = 5)\n",
    "cv_er_entry.grid(row = 12, column = 35, columnspan= 10, padx = 5, pady=5)\n",
    "ab_tpl = tk.Label(root, text = 'Abundant Template Count:')\n",
    "ab_tpl.grid(row = 12, column = 45, columnspan= 30, padx = 5, pady=5)\n",
    "ab_tpl_entry = tk.Entry(root, width = 5)\n",
    "ab_tpl_entry.grid(row = 12, column = 75, columnspan= 10, padx = 5, pady=5)\n",
    "align_error = tk.Label(root, text = 'Max Deduplication Error (bp):')\n",
    "align_error.grid(row = 13, column = 0, columnspan= 35, padx = 5, pady=5)\n",
    "align_er_entry = tk.Entry(root, width = 5)\n",
    "align_er_entry.grid(row = 13, column = 35, columnspan= 10,padx = 5, pady=5)\n",
    "prcss_num = tk.Label(root,text = 'Process Count:')\n",
    "prcss_num.grid(row = 13, column = 45, columnspan= 25, padx = 5, pady=5)\n",
    "prcss_num_entry = tk.Entry(root,width = 10)\n",
    "prcss_num_entry.grid(row = 13, column = 70, columnspan= 20, padx = 5, pady=5)\n",
    "dfp_button = tk.Button(root,text='    Use Default   \\n    Parameters   ',command = use_default_param)\n",
    "dfp_button.grid(row = 12, column = 93, columnspan = 25, rowspan = 2, padx = 5, pady=5 )\n",
    "\n",
    "submit_button = tk.Button(root,text='        >>> Submit for Translation <<<       ',command = submit1)\n",
    "submit_button.grid(row = 14, column = 5, columnspan = 65, padx = 5, pady=10 )\n",
    "react = tk.Label(root,text = '')\n",
    "react.grid(row = 14, column = 70, columnspan = 20, padx = 5, pady=10 )\n",
    "\n",
    "hyfen = tk.Label(root,text = '========== Clustering Section ============================================================================== ',font = (\"Arial\", 10, \"bold\"))\n",
    "hyfen.grid(row=15,column = 0, columnspan = 125, padx = 10, pady = 5)\n",
    "\n",
    "scale = tk.Scale(root, from_=0, to=100, orient=tk.HORIZONTAL,showvalue = True, length=300, width=10)\n",
    "scale.grid(row = 16, column = 25, columnspan= 30, padx = 5, pady=5)\n",
    "stringency = tk.Label(root, text = 'Grouping Stringency\\n (Similarity, %):  \\n\\n')\n",
    "stringency.grid(row = 16, column = 0, columnspan= 25,rowspan=2, padx = 5, pady=5)\n",
    "\n",
    "cluster_cnt = tk.Label(root, text = 'Process Count:')\n",
    "cluster_cnt.grid(row = 16, column = 55, columnspan= 20, padx = 5, pady=5)\n",
    "cluster_cnt_entry = tk.Entry(root, width = 5)\n",
    "cluster_cnt_entry.grid(row = 16, column = 75, columnspan= 10, padx = 5, pady=5)\n",
    "dfpc_button = tk.Button(root,text='  Use Default Parameters  ',command = use_default_param2)\n",
    "dfpc_button.grid(row = 16, column = 88, columnspan = 28, padx = 5, pady=5 )\n",
    "\n",
    "submit2_button = tk.Button(root,text='        >>> Submit for Clustering <<<       ',command = submit2)\n",
    "submit2_button.grid(row = 17, column = 5, columnspan = 65, padx = 5, pady=10 )\n",
    "react2 = tk.Label(root,text = '')\n",
    "react2.grid(row = 17, column = 70, columnspan = 20, padx = 5, pady=10 )\n",
    "\n",
    "root.mainloop()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
